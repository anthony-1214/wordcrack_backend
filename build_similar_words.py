"""
build_similar_words.py
å¾ word_embeddings + words ç”¢ç”Ÿã€Œæ¯å€‹å–®å­—çš„ç›¸ä¼¼å­—è¡¨ã€å¯«å…¥ MySQL çš„ similar_words è³‡æ–™è¡¨ã€‚

å‰ç½®ï¼š
1. ä½ å·²ç¶“è·‘é embed_words.pyï¼Œè³‡æ–™è¡¨ word_embeddings å·²ç¶“æœ‰è³‡æ–™ã€‚
2. backend/.env å…§è¦æœ‰ MYSQL_URLï¼Œæ¯”å¦‚ï¼š
   MYSQL_URL=mysql://root:xxxx@turntable.proxy.rlwy.net:24042/railway

3. éœ€è¦å¥—ä»¶ï¼š
   pip install pymysql numpy python-dotenv
"""

import os
import json
import traceback
from urllib.parse import urlparse

import numpy as np
import pymysql
from dotenv import load_dotenv

# -----------------------------
# è®€å– .env
# -----------------------------
load_dotenv()
MYSQL_URL = os.getenv("MYSQL_URL", "")

if not MYSQL_URL:
    raise RuntimeError("âŒ ç¼ºå°‘ MYSQL_URLï¼Œè«‹åœ¨ .env è¨­å®šï¼Œä¾‹å¦‚ï¼šmysql://root:...@host:port/railway")

# -----------------------------
# å»ºç«‹ DB é€£ç·š
# -----------------------------
def get_db():
    url = urlparse(MYSQL_URL)
    return pymysql.connect(
        host=url.hostname,
        user=url.username,
        password=url.password,
        database=url.path[1:],
        port=url.port,
        charset="utf8mb4",
        cursorclass=pymysql.cursors.DictCursor,
        autocommit=False,
    )

db = get_db()
print("âœ… å·²é€£ç·š MySQL")

# -----------------------------
# å»ºç«‹ / ç¢ºèª similar_words è³‡æ–™è¡¨
# -----------------------------
CREATE_TABLE_SQL = """
CREATE TABLE IF NOT EXISTS similar_words (
  id INT AUTO_INCREMENT PRIMARY KEY,
  base_word VARCHAR(255) NOT NULL,
  similar_word VARCHAR(255) NOT NULL,
  score FLOAT NOT NULL,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  UNIQUE KEY uq_base_sim (base_word, similar_word)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
"""

with db.cursor() as cursor:
    cursor.execute(CREATE_TABLE_SQL)
db.commit()
print("âœ… å·²ç¢ºèªå»ºç«‹è³‡æ–™è¡¨ï¼šsimilar_words")

# -----------------------------
# è®€å–æ‰€æœ‰ word + embedding
# -----------------------------
print("ğŸ“¥ è®€å– word_embeddings...")

with db.cursor() as cursor:
    cursor.execute("""
        SELECT w.id, w.word, w.chinese, e.embedding
        FROM words w
        JOIN word_embeddings e ON w.id = e.word_id
        ORDER BY w.id
    """)
    rows = cursor.fetchall()

if not rows:
    db.close()
    raise SystemExit("âŒ word_embeddings è£¡æ²’æœ‰è³‡æ–™ï¼Œè«‹å…ˆè·‘ embed_words.py")

# æº–å‚™ numpy é™£åˆ—
words = []
chinese = []
emb_list = []

for r in rows:
    words.append(r["word"])
    chinese.append(r["chinese"])
    vec = np.array(json.loads(r["embedding"]), dtype="float32")
    emb_list.append(vec)

emb_matrix = np.vstack(emb_list)  # (N, D)
N, D = emb_matrix.shape
print(f"ğŸ§® å…±è¼‰å…¥ {N} å€‹å–®å­—ï¼Œå‘é‡ç¶­åº¦ {D}")

# -----------------------------
# è¨ˆç®— cosine similarity matrix
# -----------------------------
print("âš™ï¸ æ­£è¦åŒ–å‘é‡...")
norms = np.linalg.norm(emb_matrix, axis=1, keepdims=True)
emb_norm = emb_matrix / norms

print("ğŸ”¢ è¨ˆç®— N x N ç›¸ä¼¼åº¦çŸ©é™£ï¼ˆå¯èƒ½éœ€è¦ä¸€é»æ™‚é–“ï¼‰...")
# (N, D) @ (D, N) = (N, N)
sim_matrix = np.dot(emb_norm, emb_norm.T)

# è‡ªå·±è·Ÿè‡ªå·±è¨­æˆ -infï¼Œé¿å…è¢«é¸é€²ç›¸ä¼¼å­—
np.fill_diagonal(sim_matrix, -1.0)

TOP_K = 5  # æ¯å€‹å­—å–å¹¾å€‹ç›¸ä¼¼å­—

# -----------------------------
# å¯«å…¥ similar_words
# -----------------------------
print("ğŸ“ æ¸…ç©ºèˆŠçš„ similar_words è³‡æ–™ï¼ˆå¯è¦–éœ€æ±‚ä¿ç•™ï¼‰...")
with db.cursor() as cursor:
    cursor.execute("TRUNCATE TABLE similar_words;")
db.commit()

print(f"ğŸš€ é–‹å§‹ç‚ºæ¯å€‹å–®å­—å¯«å…¥å‰ {TOP_K} å€‹ç›¸ä¼¼å­—...")

batch_values = []
BATCH_SIZE = 1000

for i in range(N):
    sims = sim_matrix[i]
    # å–å‰ TOP_K å¤§çš„ index
    if TOP_K >= N:
        top_idx = np.argsort(-sims)
    else:
        # argpartition æ¯” argsort å¿«
        top_idx = np.argpartition(-sims, TOP_K)[:TOP_K]
        top_idx = top_idx[np.argsort(-sims[top_idx])]

    base_word = words[i]

    for j in top_idx:
        sim_word = words[j]
        score = float(sims[j])
        batch_values.append((base_word, sim_word, score))

    # æ‰¹æ¬¡å¯«å…¥
    if len(batch_values) >= BATCH_SIZE:
        with db.cursor() as cursor:
            cursor.executemany(
                """
                INSERT INTO similar_words (base_word, similar_word, score)
                VALUES (%s, %s, %s)
                ON DUPLICATE KEY UPDATE
                  score = VALUES(score)
                """,
                batch_values,
            )
        db.commit()
        print(f"âœ… å·²å¯«å…¥ {len(batch_values)} ç­†ï¼ˆä¸­é€”ç´¯è¨ˆï¼‰ï¼Œç›®å‰è™•ç†åˆ°ç¬¬ {i+1} / {N} å€‹å–®å­—")
        batch_values.clear()

# å¯«å…¥å‰©é¤˜çš„
if batch_values:
    with db.cursor() as cursor:
        cursor.executemany(
            """
            INSERT INTO similar_words (base_word, similar_word, score)
            VALUES (%s, %s, %s)
            ON DUPLICATE KEY UPDATE
              score = VALUES(score)
            """,
            batch_values,
        )
    db.commit()
    print(f"âœ… æœ€å¾Œè£œå¯« {len(batch_values)} ç­†")

db.close()
print("ğŸ‰ å…¨éƒ¨å®Œæˆï¼similar_words å·²ç”Ÿæˆå…¨è¡¨ã€‚")